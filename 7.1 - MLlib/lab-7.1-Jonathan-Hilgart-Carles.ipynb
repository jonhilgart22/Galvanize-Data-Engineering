{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Movie Recommendation with MLlib\n",
    "===============================\n",
    "<!--adapted from https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html -->\n",
    "In this lab, we will use MLlib to make personalized movie recommendations tailored _for you_. We will work with 10 million ratings from 72,000 users on 10,000 movies, collected by [MovieLens](http://movielens.umn.edu/). This dataset is can be found at http://grouplens.org/datasets/movielens. You may want to start with a smaller version of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1. Data set\n",
    "------------------------------\n",
    "We will use two files from this MovieLens dataset: \"`ratings.dat`\" and \"`movies.dat`\". All ratings are contained in the file \"`ratings.dat`\" and are in the following format:\n",
    "\n",
    "    UserID::MovieID::Rating::Timestamp\n",
    "\n",
    "Movie information is in the file \"`movies.dat`\" and is in the following format:\n",
    "\n",
    "    MovieID::Title::Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2. Collaborative filtering\n",
    "------------------------------\n",
    "Collaborative filtering is commonly used for recommender systems. These techniques aim to fill in the missing entries of a user-item association matrix, in our case, the user-movie rating matrix. MLlib currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. In particular, we implement the alternating least squares (ALS) algorithm to learn these latent factors.\n",
    "<img src=\"https://databricks-training.s3.amazonaws.com/img/matrix_factorization.png\" title=\"Matrix Factorization\" alt=\"Matrix Factorization\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "3. Create training examples\n",
    "------------------------------\n",
    "To make recommendation _for you_, we are going to learn your taste by asking you to rate a few movies. We have selected a small set of movies that have received the most ratings from users in the MovieLens dataset. You can rate those movies by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys\n",
    "\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os import remove, removedirs\n",
    "from os.path import dirname, join, isfile, dirname\n",
    "from time import time\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "topMovies = \"\"\"1,Toy Story (1995)\n",
    "780,Independence Day (a.k.a. ID4) (1996)\n",
    "590,Dances with Wolves (1990)\n",
    "1210,Star Wars: Episode VI - Return of the Jedi (1983)\n",
    "648,Mission: Impossible (1996)\n",
    "344,Ace Ventura: Pet Detective (1994)\n",
    "165,Die Hard: With a Vengeance (1995)\n",
    "153,Batman Forever (1995)\n",
    "597,Pretty Woman (1990)\n",
    "1580,Men in Black (1997)\n",
    "231,Dumb & Dumber (1994)\"\"\"\n",
    "\n",
    "ratingsFile = 'personalRatings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you've already rated the movies. Overwrite ratings (y/N)? N\n"
     ]
    }
   ],
   "source": [
    "if isfile(ratingsFile):\n",
    "    r = raw_input(\"Looks like you've already rated the movies. Overwrite ratings (y/N)? \")\n",
    "    if r and r[0].lower() == \"y\":\n",
    "        remove(ratingsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not isfile(ratingsFile):\n",
    "    prompt = \"Please rate the following movie (1-5 (best), or 0 if not seen): \"\n",
    "    print prompt\n",
    "\n",
    "    now = int(time())\n",
    "    n = 0\n",
    "\n",
    "    f = open(ratingsFile, 'w')\n",
    "    for line in topMovies.split(\"\\n\"):\n",
    "        ls = line.strip().split(\",\")\n",
    "        valid = False\n",
    "        while not valid:\n",
    "            rStr = raw_input(ls[1] + \": \")\n",
    "            r = int(rStr) if rStr.isdigit() else -1\n",
    "            if r < 0 or r > 5:\n",
    "                print prompt\n",
    "            else:\n",
    "                valid = True\n",
    "                if r > 0:\n",
    "                    f.write(\"0::%s::%d::%d\\n\" % (ls[0], r, now))\n",
    "                    n += 1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After you’re done rating the movies, we save your ratings in `personalRatings.txt` in the MovieLens format, where a special user id `0` is assigned to you.\n",
    "\n",
    "`bin/rateMovies` allows you to re-rate the movies if you’d like to see how your ratings affect your recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "4. Setup\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will be using a standalone project template for this exercise.\n",
    "\n",
    "The following is the main file you are going to edit, compile, and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e177c644f8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# load personal ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mmyRatings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadRatings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mmyRatingsRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyRatings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e177c644f8c5>\u001b[0m in \u001b[0;36mloadRatings\u001b[0;34m(ratingsFile)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratingsFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparseRating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e177c644f8c5>\u001b[0m in \u001b[0;36mparseRating\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"::\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparseMovie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# %load MovieLensALS.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os.path import join, isfile, dirname\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "def parseRating(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return long(fields[3]) % 10, (int(fields[0]), int(fields[1]), float(fields[2]))\n",
    "\n",
    "def parseMovie(line):\n",
    "    \"\"\"\n",
    "    Parses a movie record in MovieLens format movieId::movieTitle .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return int(fields[0]), fields[1]\n",
    "\n",
    "def loadRatings(ratingsFile):\n",
    "    \"\"\"\n",
    "    Load ratings from file.\n",
    "    \"\"\"\n",
    "    if not isfile(ratingsFile):\n",
    "        print \"File %s does not exist.\" % ratingsFile\n",
    "        sys.exit(1)\n",
    "    f = open(ratingsFile, 'r')\n",
    "    ratings = filter(lambda r: r[2] > 0, [parseRating(line)[1] for line in f])\n",
    "    f.close()\n",
    "    if not ratings:\n",
    "        print \"No ratings provided.\"\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return ratings\n",
    "\n",
    "def computeRmse(model, data, n):\n",
    "    \"\"\"\n",
    "    Compute RMSE (Root Mean Squared Error).\n",
    "    \"\"\"\n",
    "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
    "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
    "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
    "      .values()\n",
    "    return sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if (len(sys.argv) != 3):\n",
    "        print \"Usage: /path/to/spark/bin/spark-submit --driver-memory 2g \" + \\\n",
    "          \"MovieLensALS.py movieLensDataDir personalRatingsFile\"\n",
    "        sys.exit(1)\n",
    "\n",
    "    # set up environment\n",
    "    conf = SparkConf() \\\n",
    "      .setAppName(\"MovieLensALS\") \\\n",
    "      .set(\"spark.executor.memory\", \"2g\")\n",
    "#     sc = SparkContext(conf=conf)\n",
    "\n",
    "    # load personal ratings\n",
    "    myRatings = loadRatings(sys.argv[2])\n",
    "    myRatingsRDD = sc.parallelize(myRatings, 1)\n",
    "    \n",
    "    # load ratings and movie titles\n",
    "\n",
    "    movieLensHomeDir = sys.argv[1]\n",
    "\n",
    "    # ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))\n",
    "    ratings = sc.textFile(join(movieLensHomeDir, \"ratings.dat\")).map(parseRating)\n",
    "\n",
    "    # movies is an RDD of (movieId, movieTitle)\n",
    "    movies = dict(sc.textFile(join(movieLensHomeDir, \"movies.dat\")).map(parseMovie).collect())\n",
    "\n",
    "    # your code here\n",
    "    \n",
    "    # clean up\n",
    "    sc.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let’s first take a closer look at our template code in a text editor, then we’ll start adding code to the template. Locate the MovieLensALS class and open it with a text editor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The code uses the SparkContext to read in ratings. Recall that the rating file is a text file with \"`::`\" as the delimiter. The code parses each line to create a RDD for ratings that contains `(Int, Rating)` pairs. We only keep the last digit of the timestamp as a random key. The `Rating` class is a wrapper around the tuple `(user: Int, product: Int, rating: Double)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parseRating(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return long(fields[3]) % 10, (int(fields[0]), int(fields[1]), float(fields[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "movieLensHomeDir = 's3://dsci/6007/data/MovieLens/movielens/medium/'\n",
    "\n",
    "# ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))\n",
    "ratings = sc.textFile(join(movieLensHomeDir, \"ratings.dat\")).map(parseRating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, the code read in movie ids and titles, collect them into a movie id to title map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parseMovie(line):\n",
    "    fields = line.split(\"::\")\n",
    "    return int(fields[0]), fields[1]\n",
    "\n",
    "movies = dict(sc.textFile(join(movieLensHomeDir, \"movies.dat\")).map(parseMovie).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, let’s get a summary of the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1,000,209 ratings from 6,040 users on 3,706 movies.\n"
     ]
    }
   ],
   "source": [
    "numRatings = ratings.count()\n",
    "numUsers = ratings.values().map(lambda r: r[0]).distinct().count()\n",
    "numMovies = ratings.values().map(lambda r: r[1]).distinct().count()\n",
    "\n",
    "print \"Got {:,} ratings from {:,} users on {:,} movies.\".format(numRatings, numUsers, numMovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "5. Splitting training data\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loadRatings(ratingsFile):\n",
    "    \"\"\"\n",
    "    Load ratings from file.\n",
    "    \"\"\"\n",
    "    if not isfile(ratingsFile):\n",
    "        print \"File %s does not exist.\" % ratingsFile\n",
    "        sys.exit(1)\n",
    "    f = open(ratingsFile, 'r')\n",
    "    ratings = filter(lambda r: r[2] > 0, [parseRating(line)[1] for line in f])\n",
    "    f.close()\n",
    "    if not ratings:\n",
    "        print \"No ratings provided.\"\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load personal ratings\n",
    "myRatings = loadRatings(ratingsFile)\n",
    "myRatingsRDD = sc.parallelize(myRatings, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will use MLlib’s `ALS` to train a `MatrixFactorizationModel`, which takes a `RDD[(user, product, rating)]`. ALS has training parameters such as rank for matrix factors and regularization constants. To determine a good combination of the training parameters, we split the data into three non-overlapping subsets, named training, test, and validation, based on the last digit of the timestamp, and cache them. We will train multiple models based on the training set, select the best model on the validation set based on RMSE (Root Mean Squared Error), and finally evaluate the best model on the test set. We also add your ratings to the training set to make recommendations for you. We hold the training, validation, and test sets in memory by calling cache because we need to visit them multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 602,252; validation: 198,919; test: 199,049\n"
     ]
    }
   ],
   "source": [
    "numPartitions = 4\n",
    "training = ratings.filter(lambda x: x[0] < 6) \\\n",
    "  .values() \\\n",
    "  .union(myRatingsRDD) \\\n",
    "  .repartition(numPartitions) \\\n",
    "  .cache()\n",
    "\n",
    "validation = ratings.filter(lambda x: x[0] >= 6 and x[0] < 8) \\\n",
    "  .values() \\\n",
    "  .repartition(numPartitions) \\\n",
    "  .cache()\n",
    "\n",
    "test = ratings.filter(lambda x: x[0] >= 8).values().cache()\n",
    "\n",
    "numTraining = training.count()\n",
    "numValidation = validation.count()\n",
    "numTest = test.count()\n",
    "\n",
    "print \"Training: {:,}; validation: {:,}; test: {:,}\".format(numTraining, numValidation, numTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "6. Training using ALS\n",
    "------------------------------\n",
    "In this section, we will use `ALS.train` to train a bunch of models, and select and evaluate the best. Among the training paramters of ALS, the most important ones are rank, lambda (regularization constant), and number of iterations. The `train` method of ALS we are going to use is defined as the following:\n",
    "```python\n",
    "class ALS(object):\n",
    "\n",
    "    def train(cls, ratings, rank, iterations=5, lambda_=0.01, blocks=-1):\n",
    "        # ...\n",
    "        return MatrixFactorizationModel(sc, mod)\n",
    "```\n",
    "Ideally, we want to try a large number of combinations of them in order to find the best one. Due to time constraint, we will test only 8 combinations resulting from the cross product of 2 different ranks (8 and 12), 2 different lambdas (1.0 and 10.0), and two different numbers of iterations (10 and 20). We use the provided method `computeRmse` to compute the RMSE on the validation set for each model. The model with the smallest RMSE on the validation set becomes the one selected and its RMSE on the test set is used as the final metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is has validation RMSE 1.04564380399 and test RMSE 1.0424118474, lambda 0.5, iterations 10, rank 8\n"
     ]
    }
   ],
   "source": [
    "ranks = [6, 8]\n",
    "lambdas = [.5,.8,1.0]\n",
    "numIters = [10, 20]\n",
    "bestModel = None\n",
    "rmse_val = float(\"inf\")\n",
    "best_rank = 0\n",
    "best_lambda= -1.0\n",
    "best_iteration= -1\n",
    "als = ALS()\n",
    "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
    "    model = als.train(training, rank, numIter, lmbda)\n",
    "    validationRmse = computeRmse(model, validation, numValidation)\n",
    "    if (validationRmse < rmse_val):\n",
    "        bestModel = model\n",
    "        rmse_val = validationRmse\n",
    "        best_rank = rank\n",
    "        best_lambda = lmbda\n",
    "        best_iteration= numIter\n",
    "test_rmse= computeRmse(bestModel, test, numTest)\n",
    "# evaluate the best model on the test set\n",
    "print(\"The best model is has validation RMSE {} and test RMSE {}, lambda {}, iterations {}, rank {}\".format(\n",
    "    rmse_val ,test_rmse,best_lambda, best_iteration,best_rank ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.mllib.recommendation.MatrixFactorizationModel object at 0x7f7368c4bcd0>\n"
     ]
    }
   ],
   "source": [
    "print(bestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Spark might take a minute or two to train the models. You should see the following on the screen:\n",
    "\n",
    "    The best model was trained using rank 8 and lambda 10.0, and its RMSE on test is 0.8808492431998702."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "7. Recommending movies for you\n",
    "------------------------------\n",
    "As the last part of our tutorial, let’s take a look at what movies our model recommends for you. This is done by generating `(0, movieId)` pairs for all movies you haven’t rated and calling the model’s [`predict`](https://spark.apache.org/docs/latest/api/python/_modules/pyspark/mllib/recommendation.html#MatrixFactorizationModel.predictAll) method to get predictions. `0` is the special user id assigned to you.\n",
    "```python\n",
    "class MatrixFactorizationModel(object):\n",
    "    def predictAll(self, usersProducts):\n",
    "        # ...\n",
    "        return RDD(self._java_model.predict(usersProductsJRDD._jrdd),\n",
    "                   self._context, RatingDeserializer())\n",
    "```\n",
    "After we get all predictions, let us list the top 50 recommendations and see whether they look good to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_movies_rated = [i[1] for i in myRatings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "candidate_movies = [ m for m in movies if m not in my_movies_rated]\n",
    "candidate_movies_rdd = sc.parallelize(candidate_movies )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = bestModel.predictAll(candidate_movies_rdd.map(lambda x: (0,x))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating(user=0, product=320, rating=2.308844064740798)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies for you:\n",
      " 1: I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      " 2: Time of the Gypsies (Dom za vesanje) (1989)\n",
      " 3: Smashing Time (1967)\n",
      " 4: Gate of Heavenly Peace, The (1995)\n",
      " 5: Follow the Bitch (1998)\n",
      " 6: Zachariah (1971)\n",
      " 7: Bewegte Mann, Der (1994)\n",
      " 8: Institute Benjamenta, or This Dream People Call Human Life (1995)\n",
      " 9: For All Mankind (1989)\n",
      "10: Hour of the Pig, The (1993)\n",
      "11: Man of the Century (1999)\n",
      "12: Lamerica (1994)\n",
      "13: Lured (1947)\n",
      "14: Apple, The (Sib) (1998)\n",
      "15: Sanjuro (1962)\n",
      "16: I Can't Sleep (J'ai pas sommeil) (1994)\n",
      "17: Bells, The (1926)\n",
      "18: Shawshank Redemption, The (1994)\n",
      "19: Collectionneuse, La (1967)\n",
      "20: Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "21: 24 7: Twenty Four Seven (1997)\n",
      "22: Usual Suspects, The (1995)\n",
      "23: Godfather, The (1972)\n",
      "24: Close Shave, A (1995)\n",
      "25: Big Trees, The (1952)\n",
      "26: Wrong Trousers, The (1993)\n",
      "27: Paths of Glory (1957)\n",
      "28: Soft Fruit (1999)\n",
      "29: Schindler's List (1993)\n",
      "30: Third Man, The (1949)\n",
      "31: Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "32: Raiders of the Lost Ark (1981)\n",
      "33: Rear Window (1954)\n",
      "34: Skipped Parts (2000)\n",
      "35: Celebration, The (Festen) (1998)\n",
      "36: Star Wars: Episode IV - A New Hope (1977)\n",
      "37: Double Indemnity (1944)\n",
      "38: Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)\n",
      "39: To Kill a Mockingbird (1962)\n",
      "40: Ballad of Narayama, The (Narayama Bushiko) (1982)\n",
      "41: Yojimbo (1961)\n",
      "42: Bridge on the River Kwai, The (1957)\n",
      "43: I, Worst of All (Yo, la peor de todas) (1990)\n",
      "44: Sixth Sense, The (1999)\n",
      "45: World of Apu, The (Apur Sansar) (1959)\n",
      "46: One Flew Over the Cuckoo's Nest (1975)\n",
      "47: Casablanca (1942)\n",
      "48: Grand Day Out, A (1992)\n",
      "49: Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      "50: Strangers on a Train (1951)\n"
     ]
    }
   ],
   "source": [
    "recommendations = sorted(predictions, key=lambda x: x[2], reverse=True)[:50]\n",
    "\n",
    "print \"Movies for you:\"\n",
    "for i in xrange(len(recommendations)):\n",
    "    print (\"%2d: %s\" % (i + 1, movies[recommendations[i][1]])).encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The output should be similar to\n",
    "\n",
    "    Movies recommended for you:\n",
    "     1: Silence of the Lambs, The (1991)\n",
    "     2: Saving Private Ryan (1998)\n",
    "     3: Godfather, The (1972)\n",
    "     4: Star Wars: Episode IV - A New Hope (1977)\n",
    "     5: Braveheart (1995)\n",
    "     6: Schindler's List (1993)\n",
    "     7: Shawshank Redemption, The (1994)\n",
    "     8: Star Wars: Episode V - The Empire Strikes Back (1980)\n",
    "     9: Pulp Fiction (1994)\n",
    "    10: Alien (1979)\n",
    "    ...\n",
    "\n",
    "YMMV, and don’t expect to see movies from this decade, becaused the data set is old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "8. Exercises\n",
    "------------------------------\n",
    "### 8.1 Comparing to a naïve baseline\n",
    "Does ALS output a non-trivial model? We can compare the evaluation result with a naive baseline model that only outputs the average rating (or you may try one that outputs the average rating per movie). Computing the baseline’s RMSE is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_of_ratings = ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_ratings = ratings.map( lambda x: x[1][2]).reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_rating = total_ratings / number_of_ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.581564453029317"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## get the average rating for our rated movies\n",
    "my_ratings = [i[2] for i in myRatings]\n",
    "avg_vector = [average_rating for _ in range(len(myRatings))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_rmse = np.linalg.norm(np.array(avg_vector) - np.array(my_ratings))/sqrt(len(avg_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3278188379711944"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## next, get the movies we have already rated and see what the RMSE is to predict the ratings for these movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_rated_movies = [i[1] for i in myRatings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get the RMSE\n",
    "model_rmse = np.linalg.norm(np.array([bestModel.predict(0, i) for i in my_rated_movies])-np.array(my_ratings))/\\\n",
    " sqrt(len(my_rated_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performs 3.231833% better compared to the average rating\n"
     ]
    }
   ],
   "source": [
    "print(\"The model performs {:2%} better compared to the average rating\".format((average_rmse- model_rmse)/model_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The output should be similar to\n",
    "\n",
    "    The best model improves the baseline by 20.96%.\n",
    "\n",
    "It seems obvious that the trained model would outperform the naive baseline. However, a bad combination of training parameters would lead to a model worse than this naive baseline. Choosing the right set of parameters is quite important for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 8.2. Augmenting matrix factors\n",
    "In this tutorial, we add your ratings to the training set. A better way to get the recommendations for you is training a matrix factorization model first and then augmenting the model using your ratings. If this sounds interesting to you, you can take a look at the implementation of [MatrixFactorizationModel](https://spark.apache.org/docs/latest/api/python/_modules/pyspark/mllib/recommendation.html#MatrixFactorizationModel) and see how to update the model for new users and new movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
