{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "import datetime\n",
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# bart data\n",
    "bart_arrival = spark.read.parquet(\"s3a://normalized-data-weather-bart/bart_arrival_0_2017/03/04/*\")\n",
    "bart_physical = spark.read.parquet(\"s3a://normalized-data-weather-bart/bart_physical_0_2017/03/04/*\")\n",
    "# weather data\n",
    "wind_table = spark.read.parquet(\"s3a://normalized-data-weather-bart/wind_df2017/03/04/*\")\n",
    "main_temp_table = spark.read.parquet(\"s3a://normalized-data-weather-bart/main-temp2017/03/04/*\")\n",
    "weather_description_table = spark.read.parquet(\"s3a://normalized-data-weather-bart/weather-description2017/03/04/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bart_arrival_renamed = bart_arrival.select(col('origin_station_0').alias('origin_station_arrival'),\\\n",
    "                    col(\"sf_time_0\").alias(\"sf_time_arrival\"),col(\"date_0\").alias(\"date_arrival\"),\n",
    "                    col(\"direction_0\").alias(\"direction_arrival\"),col(\"hour_0\").alias(\"hour_arrival\"),\n",
    "                    col(\"minutes_til_arrival_0\").alias(\"minutes_til_arrival_bart_arrival\"),\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = '03/03/2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = datetime.datetime.strptime(t, '%M/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:2] # month\n",
    "t[3:5] #day\n",
    "t[6:] #year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def change_time_format(time):\n",
    "    month = t[:2]\n",
    "    day = t[3:5]\n",
    "    year = t[6:]\n",
    "    date_time= datetime.datetime(int(year),int(month),int(day))\n",
    "    return date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 3, 3, 0, 0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_time_format(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "joined_bart_arrival_physical_df = bart_arrival_renamed.join(bart_physical, \\\n",
    "            on = [bart_physical['origin_station_0']==bart_arrival_renamed['origin_station_arrival'],\\\n",
    "                 bart_physical['sf_time_0']==bart_arrival_renamed['sf_time_arrival'],\\\n",
    "                 bart_physical['direction_0']==bart_arrival_renamed['direction_arrival'],\\\n",
    "                 bart_physical['date_0']==bart_arrival_renamed['date_arrival']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_joined_bart_df = joined_bart_arrival_physical_df.select(\"origin_station_0\",\"sf_time_0\",\"date_0\",\"direction_0\",\n",
    "                                                             \"destination_0\",\"hour_0\",\"color_0\",\"bike_flag_0\",\n",
    "                                                             \"train_size_0\",\"capacity_0\",\"minutes_til_arrival_bart_arrival\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------+-----------+-------------+------+-------+-----------+------------+----------+--------------------------------+\n",
      "|    origin_station_0|      sf_time_0|    date_0|direction_0|destination_0|hour_0|color_0|bike_flag_0|train_size_0|capacity_0|minutes_til_arrival_bart_arrival|\n",
      "+--------------------+---------------+----------+-----------+-------------+------+-------+-----------+------------+----------+--------------------------------+\n",
      "|Pleasant Hill/Con...|05:50:01 PM PST|03/03/2017|      North|North Concord|     1| YELLOW|          1|           9|      1800|                              13|\n",
      "|Pleasant Hill/Con...|05:50:01 PM PST|03/03/2017|      South|   SF Airport|     1| YELLOW|          1|          10|      2000|                              13|\n",
      "+--------------------+---------------+----------+-----------+-------------+------+-------+-----------+------------+----------+--------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_joined_bart_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## convert the string date to datetime format\n",
    "final_joined_bart_df_dt = final_joined_bart_df.withColumn('date_0', rearrange_time (col('date_0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------+-----------+-------------------+------+-------+-----------+------------+----------+--------------------------------+\n",
      "|    origin_station_0|      sf_time_0|    date_0|direction_0|      destination_0|hour_0|color_0|bike_flag_0|train_size_0|capacity_0|minutes_til_arrival_bart_arrival|\n",
      "+--------------------+---------------+----------+-----------+-------------------+------+-------+-----------+------------+----------+--------------------------------+\n",
      "|Pleasant Hill/Con...|05:50:01 PM PST|2017-03-03|      North|      North Concord|     1| YELLOW|          1|           9|      1800|                              13|\n",
      "|Pleasant Hill/Con...|05:50:01 PM PST|2017-03-03|      South|         SF Airport|     1| YELLOW|          1|          10|      2000|                              13|\n",
      "|    19th St. Oakland|05:50:01 PM PST|2017-03-03|      North|      North Concord|     1| YELLOW|          1|          10|      2000|                               3|\n",
      "|    19th St. Oakland|05:50:01 PM PST|2017-03-03|      South|        24th Street|     1| YELLOW|          1|           9|      1800|                               1|\n",
      "|         Balboa Park|05:50:01 PM PST|2017-03-03|      North|  Dublin/Pleasanton|     1|   BLUE|          1|           8|      1600|                               6|\n",
      "|         Balboa Park|05:50:01 PM PST|2017-03-03|      South|          Daly City|     1|  GREEN|          1|          10|      2000|                               4|\n",
      "|Civic Center/UN P...|05:50:01 PM PST|2017-03-03|      North|  Dublin/Pleasanton|     1|   BLUE|          1|           9|      1800|                               3|\n",
      "|Civic Center/UN P...|05:50:01 PM PST|2017-03-03|      South|        24th Street|     1| YELLOW|          1|           9|      1800|                               4|\n",
      "|       Castro Valley|05:50:01 PM PST|2017-03-03|      North|  Dublin/Pleasanton|     1|   BLUE|          1|           8|      1600|                              15|\n",
      "|       Castro Valley|05:50:01 PM PST|2017-03-03|      South|          Daly City|     1|   BLUE|          1|           9|      1800|                               7|\n",
      "|             Fremont|05:50:01 PM PST|2017-03-03|      North|           Richmond|     1| ORANGE|          1|           7|      1400|                              11|\n",
      "|             Fremont|05:50:01 PM PST|2017-03-03|      South|          Daly City|     1|  GREEN|          1|          10|      2000|                               0|\n",
      "|        West Oakland|05:50:01 PM PST|2017-03-03|      North|  Dublin/Pleasanton|     1|   BLUE|          1|           9|      1800|                               2|\n",
      "|        West Oakland|05:50:01 PM PST|2017-03-03|      South|        24th Street|     1| YELLOW|          1|           9|      1800|                               8|\n",
      "|           San Bruno|05:50:01 PM PST|2017-03-03|      North|Pittsburg/Bay Point|     1| YELLOW|          1|          10|      2000|                               9|\n",
      "|           San Bruno|05:50:01 PM PST|2017-03-03|      South|           Millbrae|     1|    RED|          1|           8|      1600|                              13|\n",
      "|            Millbrae|05:50:01 PM PST|2017-03-03|      North|           Richmond|     1|    RED|          1|           9|      1800|                              12|\n",
      "|               Colma|05:50:01 PM PST|2017-03-03|      North|Pittsburg/Bay Point|     1| YELLOW|          1|          10|      2000|                               1|\n",
      "|               Colma|05:50:01 PM PST|2017-03-03|      South|           Millbrae|     1|    RED|          1|           8|      1600|                               6|\n",
      "|    16th St. Mission|05:50:01 PM PST|2017-03-03|      North|  Dublin/Pleasanton|     1|   BLUE|          1|           9|      1800|                               0|\n",
      "+--------------------+---------------+----------+-----------+-------------------+------+-------+-----------+------------+----------+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_joined_bart_df_dt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_bart_df = final_joined_bart_df_dt.select(dayofmonth(col('date_0')).alias(\"day_of_month\"),\n",
    "                           month(col(\"date_0\")).alias(\"month_n\"),\n",
    "                               \"origin_station_0\",\"sf_time_0\",\"date_0\",\n",
    "                              \"direction_0\", \"hour_0\",\"bike_flag_0\",\"train_size_0\",\"capacity_0\",\n",
    "                              \"minutes_til_arrival_bart_arrival\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sqlContext.registerDataFrameAsTable(final_bart_df,\"final_bart_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_bart_df = sqlContext.sql(\"\"\"SELECT count(bike_flag_0) as total_number_of_trains,origin_station_0,date_0,direction_0,\n",
    "    SUM (train_size_0) as total_number_train_cars, sum(capacity_0) as total_capacity,month_n,day_of_month\n",
    "     FROM  final_bart_df\n",
    "                WHERE minutes_til_arrival_bart_arrival <5 \n",
    "                GROUP BY origin_station_0,date_0,direction_0,month_n,day_of_month\n",
    "                ORDER BY total_capacity DESC\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## bring in weather data to ultimately join with bart data and feed into our ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wind_table_alias = wind_table.select(col(\"hour\").alias(\"hour_wind\"),col(\"date\").alias(\"date_wind\"),\"speed\",\"deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wind_temp_table = wind_table_alias .join(main_temp_table, on=[wind_table_alias ['hour_wind']==main_temp_table['hour'],\n",
    "                                    wind_table_alias ['date_wind']==main_temp_table['date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wind_temp_table_final = wind_temp_table.select(\"hour\",\"date\",\"speed\",\"deg\",\"pressure\",\"temp\",\"temp_max\",\"temp_min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_des_final = weather_description_table.select(col(\"col\").alias('weather_des'),\n",
    "                                \"hour\",\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_des_final.registerTempTable(\"weather_des_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_des_ints = sqlContext.sql(\"\"\"SELECT hour as hour_des,date as date_des,weather_des,\n",
    "     CASE WHEN weather_des = 'Rain' THEN 1.0\n",
    "         WHEN weather_des = 'Mist' THEN .1\n",
    "         ELSE 0.0 end as weather_precip\n",
    "       FROM  weather_des_final  \n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_des_ints_final =  weather_des_ints .select(\"hour_des\",\"date_des\",\"weather_precip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## join weather des with the other two weather tables\n",
    "\n",
    "combo_df = wind_temp_table_final.join(weather_des_ints_final, on =[wind_temp_table_final['date']==weather_des_ints_final['date_des'],\n",
    "                                           wind_temp_table_final['hour']==weather_des_ints_final['hour_des']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_df = combo_df.select(\"hour\",\"date\",\"speed\",\"deg\",\"pressure\",\"temp\",\"temp_max\",\"temp_min\",\"weather_precip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert the date string into the date format for spark\n",
    "combo_df = combo_df.withColumn('date', rearrange_time(col('date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## finally, select all of the columns\n",
    "## drop duplicates to ensure we only have only weather forecast per hour\n",
    "final_weather_df = combo_df.select(dayofmonth(col('date')).alias(\"day_of_month_weather\"),\n",
    "                           month(col(\"date\")).alias(\"month_n_weather\"),\n",
    "               \"hour\",\"date\",\"speed\",\"deg\",\"pressure\",\"temp\",\"temp_max\",\n",
    "                                   \"temp_min\",\"weather_precip\").dropDuplicates(\n",
    "    ['day_of_month_weather','month_n_weather','hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## confirm one forecast per hour\n",
    "# final_weather_df.where(col(\"hour\")=='9').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[day_of_month_weather: int, month_n_weather: int, hour: int, date: date, speed: double, deg: double, pressure: bigint, temp: double, temp_max: double, temp_min: double, weather_precip: decimal(2,1)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weather_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----+----------+-----+-------+--------+-----+--------+--------+--------------+\n",
      "|day_of_month_weather|month_n_weather|hour|      date|speed|    deg|pressure| temp|temp_max|temp_min|weather_precip|\n",
      "+--------------------+---------------+----+----------+-----+-------+--------+-----+--------+--------+--------------+\n",
      "|                   3|              3|   1|2017-03-03|10.29|  340.0|    1009|61.43|    80.6|    53.6|           0.0|\n",
      "|                   3|              3|   8|2017-03-03| 8.05|  250.0|    1016|50.65|    77.0|    30.2|           0.0|\n",
      "|                   3|              3|  10|2017-03-03| 7.18|270.006|    1036|50.36|    75.2|    30.2|           1.0|\n",
      "|                   3|              3|  19|2017-03-03|12.75|  210.0|    1017|57.63|    62.6|    53.6|           0.0|\n",
      "|                   3|              3|   9|2017-03-03| 9.17|  260.0|    1016|47.88|    53.6|    30.2|           0.0|\n",
      "|                   3|              3|   3|2017-03-03|19.46|  270.0|    1016|49.71|    53.6|    33.8|           0.0|\n",
      "|                   3|              3|   4|2017-03-03| 9.73|290.001|    1017|48.51|    53.6|    32.0|           0.0|\n",
      "|                   3|              3|  21|2017-03-03|16.11|  190.0|    1015|59.45|    62.6|    55.4|           0.0|\n",
      "|                   3|              3|  16|2017-03-03| 8.05|  170.0|    1016|51.78|    53.6|    48.2|           0.1|\n",
      "|                   3|              3|  14|2017-03-03| 6.93|  120.0|    1016|51.06|    77.0|    37.4|           0.0|\n",
      "|                   3|              3|  13|2017-03-03| 8.05|  280.0|    1016|50.59|    77.0|    30.2|           0.1|\n",
      "|                   3|              3|   0|2017-03-03|11.41|   20.0|    1008| 62.1|    80.6|    46.4|           0.0|\n",
      "|                   3|              3|   2|2017-03-03|19.46|  270.0|    1009|56.44|    78.8|    37.4|           0.0|\n",
      "|                   3|              3|  15|2017-03-03| 7.74|263.001|    1036|49.86|    53.6|    48.2|           0.1|\n",
      "|                   3|              3|   6|2017-03-03| 6.93|  280.0|    1017|48.52|    53.6|    32.0|           0.0|\n",
      "|                   3|              3|  23|2017-03-03| 5.82|   10.0|    1035|64.74|    84.2|    46.4|           0.0|\n",
      "|                   3|              3|  17|2017-03-03|10.29|  170.0|    1035|54.05|    57.2|    51.8|           0.1|\n",
      "|                   3|              3|  18|2017-03-03|10.29|  230.0|    1016|57.04|    60.8|    53.6|           0.1|\n",
      "|                   3|              3|   7|2017-03-03| 8.52|279.002|    1017|48.69|    53.6|    32.0|           0.0|\n",
      "|                   3|              3|  22|2017-03-03|12.77|224.501|    1030|59.32|    62.6|    55.4|           0.0|\n",
      "+--------------------+---------------+----+----------+-----+-------+--------+-----+--------+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_weather_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_number_of_trains: bigint, origin_station_0: string, date_0: date, direction_0: string, total_number_train_cars: bigint, total_capacity: bigint, month_n: int, day_of_month: int]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bart_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------------+----------+-----------+-----------------------+--------------+-------+------------+\n",
      "|total_number_of_trains|    origin_station_0|    date_0|direction_0|total_number_train_cars|total_capacity|month_n|day_of_month|\n",
      "+----------------------+--------------------+----------+-----------+-----------------------+--------------+-------+------------+\n",
      "|                   369|           Fruitvale|2017-03-03|      North|                   3017|        603400|      3|           3|\n",
      "|                   218|           Fruitvale|2017-03-03|      South|                   1910|        382000|      3|           3|\n",
      "|                   133|            Millbrae|2017-03-03|      North|                   1248|        249600|      3|           3|\n",
      "|                   114|         Balboa Park|2017-03-03|      South|                    893|        178600|      3|           3|\n",
      "|                    99|West Dublin/Pleas...|2017-03-03|      South|                    873|        174600|      3|           3|\n",
      "|                    99|           Daly City|2017-03-03|      North|                    869|        173800|      3|           3|\n",
      "|                   109|    24th St. Mission|2017-03-03|      South|                    821|        164200|      3|           3|\n",
      "|                   106|Civic Center/UN P...|2017-03-03|      South|                    784|        156800|      3|           3|\n",
      "|                   105|    16th St. Mission|2017-03-03|      South|                    763|        152600|      3|           3|\n",
      "|                    93|         San Leandro|2017-03-03|      North|                    741|        148200|      3|           3|\n",
      "|                    90|            Coliseum|2017-03-03|      North|                    711|        142200|      3|           3|\n",
      "|                    98|         Embarcadero|2017-03-03|      South|                    705|        141000|      3|           3|\n",
      "|                    92|        West Oakland|2017-03-03|      South|                    695|        139000|      3|           3|\n",
      "|                    95|      Montgomery St.|2017-03-03|      South|                    685|        137000|      3|           3|\n",
      "|                    69|           MacArthur|2017-03-03|      North|                    665|        133000|      3|           3|\n",
      "|                    68|North Concord/Mar...|2017-03-03|      North|                    663|        132600|      3|           3|\n",
      "|                   105|               Ashby|2017-03-03|      North|                    654|        130800|      3|           3|\n",
      "|                   104|   Downtown Berkeley|2017-03-03|      North|                    649|        129800|      3|           3|\n",
      "|                   103|      North Berkeley|2017-03-03|      North|                    645|        129000|      3|           3|\n",
      "|                    69|San Francisco Int...|2017-03-03|      North|                    644|        128800|      3|           3|\n",
      "+----------------------+--------------------+----------+-----------+-----------------------+--------------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_bart_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_table = final_weather_df.join(final_bart_df, on =[final_weather_df['date']==final_bart_df['date_0'],\n",
    "                                         ]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_bart_weather_table = temp_table.select(\"day_of_month\",\"month_n\",\"total_capacity\",\"total_number_train_cars\",\n",
    "                                         \"direction_0\",\"date_0\",\"origin_station_0\",\"weather_precip\",\n",
    "                                         \"speed\",\"deg\",\"pressure\",\"temp\",\"temp_max\",\"temp_min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## next, load the GB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1037.load.\n: org.apache.hadoop.mapred.InvalidInputException: Input Pattern s3a://predicting-bart-ridership-model/*/*/*/metadata matches 0 files\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:253)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:201)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:281)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:202)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1332)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1326)\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1367)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1366)\n\tat org.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:379)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:322)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-9323cd0800c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGBTRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3a://predicting-bart-ridership-model/*/*/*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a basestring, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clazz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_from_java\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             raise NotImplementedError(\"This Java ML type cannot be loaded into Python currently: %r\"\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1037.load.\n: org.apache.hadoop.mapred.InvalidInputException: Input Pattern s3a://predicting-bart-ridership-model/*/*/*/metadata matches 0 files\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:253)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:201)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:281)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:202)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1332)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1326)\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1367)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1366)\n\tat org.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:379)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:322)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "gb_model = GBTRegressor.load(\"s3a://predicting-bart-ridership-model/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sameModel = LogisticRegressionModel.load(sc, \"lrm_model.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
