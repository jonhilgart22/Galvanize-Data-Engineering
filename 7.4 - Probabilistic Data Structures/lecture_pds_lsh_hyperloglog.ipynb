{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "Probabilistic Data Structures\n",
    "===\n",
    "\n",
    "<img src=\"http://www.awesomedice.com/blog/wp-content/uploads/2013/08/1-sided-dice.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "<details><summary>\n",
    "What is this? Is it probablistic?\n",
    "</summary>\n",
    "Nope - 1 sided coin\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Probabilistic Data Structures\n",
    "---\n",
    "\n",
    "1. Bloom filter\n",
    "2. Count‚Äìmin sketch  \n",
    "3. _Locality-sensitive hashing (LSH)_\n",
    "4. _HyperLogLog_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "Imagine you are higher as the 1st Data Scientist at an employment website...\n",
    "\n",
    "<img src=\"images/matching.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "<details><summary>\n",
    "What is this class of problem?\n",
    "</summary>\n",
    "Bipartite graph matching\n",
    "</details>\n",
    "<br>\n",
    "<details><summary>\n",
    "Approximately, how does scale with no apoiri information? How many more edges are there for each new node?\n",
    "</summary>\n",
    "polynominal / O(n^2)\n",
    "</details>\n",
    "<br>\n",
    "<details><summary>\n",
    "What is the class of algorithms to solve this time of matching problem?</summary>\n",
    "Stable marriage  \n",
    "<br>\n",
    "Gale Shapley Algorithm is the classic and one of the best:\n",
    "It involves a number of \"rounds\" (or \"iterations\"). In the first round, first a) each unengaged man proposes to the woman he prefers most, and then b) each woman replies \"maybe\" to her suitor she most prefers and \"no\" to all other suitors. She is then provisionally \"engaged\" to the suitor she most prefers so far, and that suitor is likewise provisionally engaged to her. In each subsequent round, first a) each unengaged man proposes to the most-preferred woman to whom he has not yet proposed (regardless of whether the woman is already engaged), and then b) each woman replies \"maybe\" if she is currently not engaged or if she prefers this guy over her current provisional partner (in this case, she rejects her current provisional partner who becomes unengaged). The provisional nature of engagements preserves the right of an already-engaged woman to \"trade up\" (and, in the process, to \"jilt\" her until-then partner). This process is repeated until everyone is engaged.\n",
    "<br>\n",
    "Or [if you wanted to match companies to investors](https://blog.ycombinator.com/investor-day)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does this work with millions of jobs and job seekers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "Locality-sensitive hashing (LSH)\n",
    "----\n",
    "\n",
    "<img src=\"images/lsh_overview.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "- Locality-sensitive hashing (LSH) does approximate set similarity\n",
    "- It hashes to cluster similar items. \"Similar\" items are likely to be hashed to the same bucket (with high probability)\n",
    "- Avoids all-pairs / Cartesian-product comparison hell. üí•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "What is the Minimum Viable Product(MVP) for set similarity? Jaccard Distance Flashback\n",
    "---\n",
    "\n",
    "### Jaccard Distance Flashback\n",
    "<img src=\"images/jaccard.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/jaccard_formula.png\" style=\"width: 400px;\"/>\n",
    "---\n",
    "Check for understanding\n",
    "---\n",
    "\n",
    "<details><summary>\n",
    "When would a data scientist use this?\n",
    "</summary>\n",
    "Build a recommender system! This is 2nd simplest method.<br>\n",
    "S√∏rensen‚ÄìDice coefficient is the simplest! <br>\n",
    "[Learn more here](http://infolab.stanford.edu/~ullman/mmds/ch9.pdf)\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Encoding sets as bit vectors\n",
    "---   \n",
    "\n",
    "- We can encode sets using 0 or 1 (Bit/Boolean) vectors\n",
    "‚Äì One dimension per element in the universal set\n",
    "- Interpretation:\n",
    "    - Set intersection as bitwise AND \n",
    "    - Set union as bitwise OR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Student Activity\n",
    "---\n",
    "\n",
    "Given these bit vectors:  \n",
    "v1 = 10111  \n",
    "v2 = 10011  \n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "- What is the size of the intersection?\n",
    "- What is the size of the union?\n",
    "- What is the Jaccard similarity?\n",
    "- What is the Jaccard distance?\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<details><summary>\n",
    "Click here for solutions.\n",
    "</summary>\n",
    "Size of intersection = 3 <br>\n",
    "Size of union = 4 <br>\n",
    "Jaccard similarity= 3/4 <br>\n",
    "d(x,y) = 1‚Äì(Jaccardsimilarity) = 1/4 <br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Locality-Sensitive Hashing (LSH) \n",
    "----\n",
    "\n",
    "LSH is a general method for finding approximate near-neighbors in high-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "What are some applications of LSH?\n",
    "---\n",
    "\n",
    "- Given a large number (N in the millions or even billions) of text documents, find pairs that are ‚Äúnear duplicates‚Äù\n",
    "- Mirror websites, or approximate mirrors. Don‚Äôt want to show both in a search\n",
    "- Plagiarism, including large quotations.\n",
    "- Web spam detection\n",
    "- Similar news articles at many news sites. Cluster articles by ‚Äúsame story.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Check for understanding\n",
    "---\n",
    "\n",
    "<details><summary>\n",
    "How would you find extact matches for documents (aka, strings)?\n",
    "</summary>\n",
    "Hash map!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "How to apply LSH to find near-duplicates documents\n",
    "---\n",
    "\n",
    "- Embed documents into a vector space (use a \"shingle\" or doc2vec)\n",
    "- Then hash documents into buckets and expect that ‚Äúmost‚Äù similar documents would hash into the same bucket\n",
    "- Compare pairs of docs in each bucket to see if they are really near-duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "Min-hashing for making singles (if you don't have doc2vec)\n",
    "---\n",
    "\n",
    "<img src=\"https://moinakg.files.wordpress.com/2012/10/minhash-small.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "- Clearly, the hash function depends on the similarity metric\n",
    "- Not all similarity metrics have a suitable hash function\n",
    "- Fortunately, there is a suitable hash function for Jaccard similarity __Min-hashing__*\n",
    "\n",
    "*: This is very \"hand wavy\". You should check out [Min-hashing on your own](https://www.cs.utah.edu/~jeffp/teaching/cs5955/L5-Minhash.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Check for understanding\n",
    "---\n",
    "\n",
    "<details><summary>\n",
    "How does LSH compare to standard hashing with regard to collisions?\n",
    "</summary>\n",
    "It is the opposite, in LSH you want collisons\n",
    "\n",
    "![](http://cybertron.cg.tu-berlin.de/pdci08/imageflight/pics/general_vs_lsh.jpg)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "LSH hashing in n dimensions\n",
    "---\n",
    "<img src=\"images/lsh2_mod_4.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/lsh.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Curse of Dimensionality\n",
    "---\n",
    "\n",
    "<img src=\"http://www.iro.umontreal.ca/~bengioy/yoshua_en/research_files/CurseDimensionality.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "---\n",
    "Student discussion\n",
    "---\n",
    "\n",
    "<details><summary>\n",
    "In your own words, how does _Curse of Dimensionality_ effect finding neighbors?\n",
    "</summary>\n",
    "![](images/curse.png)\n",
    "- Let‚Äôs take a data set with a fixed number N of points. <br>\n",
    "- As we increase the number of dimensions in which these points are embedded, the average distance between points keeps increasing. <br>\n",
    "- Fewer ‚Äúneighbors‚Äù on average within a certain radius of any given point <br>\n",
    "</details>\n",
    "\n",
    "[Source](http://web.stanford.edu/class/cs345a/slides/04-highdim.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "How do companies use LSH?\n",
    "---\n",
    "\n",
    "<img src=\"http://giveitlove.com/wp-content/uploads/youtube-ads8.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "YouTube uses for video ad serving. LSH is approximate, fast, and scales.\n",
    "\n",
    "<img src=\"images/images.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "Airbnb uses it recommend similar properties based on images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Python Implement? Hell Yeah!\n",
    "-----\n",
    "\n",
    "https://github.com/kayzh/LSHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "LSH Pro Tips\n",
    "---\n",
    "\n",
    "- EMBED ALL THE THINGS! Put metadata and user features into the vector space along with the primary data\n",
    "- Hash items to overlapping buckets to make sure you don't miss near-matches. Create different sets of buckets (it is cheap and fast to hash)\n",
    "- Use all kinds of hashes\n",
    "<img src=\"images/Spherical_Hashing_Figure.png\" style=\"width: 400px;\"/>\n",
    "<br>\n",
    "<img src=\"http://sglab.kaist.ac.kr/VLSH/voronoi_region.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Additional Resources\n",
    "----\n",
    "\n",
    "- [LSH in Spark](https://github.com/mrsqueeze/spark-hash)\n",
    "- [Use LSH to rank in high dimensional spaces](https://www.youtube.com/watch?v=8NNW2kta8og)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "----\n",
    "Check for understanding\n",
    "---\n",
    "\n",
    "<details><summary>\n",
    "If I wanted to estimate frequency, which data structure would I use?\n",
    "</summary>\n",
    "Count-Min Sketch<br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "---\n",
    "Summary Table\n",
    "----\n",
    "\n",
    "| Problem | Solution  |  \n",
    "|:-------:|:------:|\n",
    "| Set Membership | Bloom Filter  |\n",
    "| Frequency summaries | Count-Min Sketch |\n",
    "| Set similarity | LSH |  \n",
    "| Cardinality estimation | HyperLogLog |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src=\"http://il2.picdn.net/shutterstock/videos/3443126/thumb/6.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "Imagine you are flipping quarters in a row and want to keep track how fips happened\n",
    "\n",
    "You could store every \"transaction\" (i.e., flip).\n",
    "\n",
    "__OR__ you store some metadata - The number of heads in a row you have seen. That single integer is can then be used to estimate the true answer.\n",
    "\n",
    "That is the intuition behind HyperLogLog:\n",
    "\n",
    "- Long runs of HEADs in random series are rare.\n",
    "- The longer you look, the more likely you see a long one.\n",
    "- Long runs are very rare and are correlated with how many coins you‚Äôve flipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "HyperLogLog does approximate count distinct\n",
    "----\n",
    "\n",
    "<img src=\"http://cdn.meme.am/instances/62976889.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "Remember count distinct is a common data query but is very computational expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "HyperLogLog Basic algorithm:\n",
    "----\n",
    "\n",
    "### Item tracking\n",
    "- n=0\n",
    "- For each input item:\n",
    "    - Hash item into bit string\n",
    "    - Count trailing zeroes in bit string\n",
    "    - If this count > n:\n",
    "        - Let n = count\n",
    "        \n",
    "Thus, we store only the maximum number of consecutive zeroes, and use that number to predict the cardinality of the entire stream.\n",
    "\n",
    "### Toy Example\n",
    "For example, given 4 bits there exist only 16 possible representations, with patterns of max consecutive zeroes shown below:\n",
    "\n",
    "0 zero\n",
    "1111\n",
    "\n",
    "7 patterns with 1 zero  \n",
    "0111, 1011, 1101, 1110, 0101, 1010, 0110\n",
    "\n",
    "5 patterns with 2 zero  \n",
    "0011, 1001, 1100, 0100, 0010\n",
    "\n",
    "2 patterns with 3 zeros  \n",
    "0001, 1000\n",
    "\n",
    "__1 pattern with 4 zeros__  \n",
    "0000\n",
    "\n",
    "So, if in our stream the highest number of consecutive zeroes is 4 we can assume we have seen 16 different patterns\n",
    "\n",
    "<img src=\"images/hyper.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "#### Item lookup\n",
    "Estimated cardinality (‚Äúcount distinct‚Äù) = $2^n$\n",
    "\n",
    "[Source](http://blog.kiip.me/engineering/sketching-scaling-everyday-hyperloglog/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Collection of random HyperLogLog factoids:\n",
    "---\n",
    "\n",
    "- We need a ‚Äúgood‚Äù hashing function to ensure that the probability of seeing any single pattern is equal to all others. \n",
    "- Supports adding entries but not removing\n",
    "- Counters can be merged (union) but not intersected\n",
    "- [This Google paper is very cool](https://stefanheule.com/papers/edbt13-hyperloglog.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Probabilistic data structures not covered\n",
    "----\n",
    "\n",
    "- MinHash (set similarity)\n",
    "- Skip list (ordered sequence search)\n",
    "- Kinetic hanger\n",
    "- Kinetic heater\n",
    "- Quotient filter\n",
    "- Random binary tree\n",
    "- Random tree\n",
    "- Rapidly exploring random tree\n",
    "- Treap\n",
    "\n",
    "[Old School Paper](http://theory.stanford.edu/~matias/papers/ads.pdf) with more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Summary\n",
    "----\n",
    "\n",
    "- Probabilistic Data Structures\n",
    "    - Use less space than a full dataset\n",
    "    - Require higher CPU load because you are doing additional processing before storage\n",
    "    - Often are stream-friendly\n",
    "- Remember to control error rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
