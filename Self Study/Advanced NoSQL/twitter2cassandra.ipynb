{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster(['ec2-54-210-40-33.compute-1.amazonaws.com'])\n",
    "\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary package to process data in JSON format\n",
    "try:\n",
    "    import json\n",
    "except ImportError:\n",
    "    import simplejson as json\n",
    "\n",
    "# Import the necessary methods from \"twitter\" library\n",
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "\n",
    "# Variables that contains the user credentials to access Twitter API\n",
    "ACCESS_TOKEN = '243404150-gpJjlAII45RoGQvFmbw3X7zBB7clv0VBcfCuu3Za'\n",
    "ACCESS_SECRET = 'd3KllH1qmUKvyWYhszcslZh0mwfvMSXhLWS1N9Vv2o0GQ'\n",
    "CONSUMER_KEY = 'Uj8qQJ1D6Wj1xyib4UVw'\n",
    "CONSUMER_SECRET = '70iwVA0LR8Lz6DeYSibzSlAgHggnJZgg32xnK6tBdzs'\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initiate the connection to Twitter Streaming API\n",
    "twitter_stream = TwitterStream(auth=oauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_ddl = '''CREATE KEYSPACE twitter \n",
    "        WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 3};\n",
    "    USE twitter;\n",
    "    CREATE TABLE tweets (\n",
    "        tweet_id bigint PRIMARY KEY,\n",
    "        created_at timestamp,\n",
    "        user_name varchar,\n",
    "        tweet_text text,\n",
    "        favorite_count int,\n",
    "        retweet_count int,\n",
    "        entities text);'''\n",
    "if False:\n",
    "    session.execute(tweet_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = twitter_stream.statuses.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 600.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 600.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.cluster:Host 54.164.67.97 has been marked down\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 2.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 4.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 8.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 16.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.connection:Heartbeat failed for connection (4366109584) to 54.164.67.97\n",
      "WARNING:cassandra.cluster:Host 54.164.67.97 has been marked down\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 2.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 32.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 4.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 8.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 16.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 32.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 64.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.67.97, scheduling retry in 64.0 seconds: [Errno 61] Tried connecting to [('54.164.67.97', 9042)]. Last error: Connection refused\n"
     ]
    }
   ],
   "source": [
    "tweet_count = 0\n",
    "for tweet in iterator:\n",
    "    if 'id' in tweet:\n",
    "        tweet_count += 1\n",
    "        row = (tweet['id'], str(pd.to_datetime(tweet.get('created_at'))),\n",
    "               tweet['user'].get('name'), tweet.get('text'),\n",
    "               tweet.get('favorite_count'), tweet.get('retweet_count'),\n",
    "               json.dumps(tweet.get('entities')))\n",
    "        session.execute(\"\"\"INSERT INTO twitter.tweets \n",
    "                (tweet_id, created_at, user_name, tweet_text, favorite_count, retweet_count, entities) \n",
    "            VALUES (%s,%s,%s,%s,%s,%s,%s)\"\"\", row)\n",
    "    if tweet_count > 99:\n",
    "        stdout.write('.')\n",
    "        tweet_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.connection:Heartbeat failed for connection (4465091600) to 54.164.199.173\n",
      "WARNING:cassandra.cluster:Host 54.164.199.173 has been marked down\n",
      "WARNING:cassandra.cluster:[control connection] Error connecting to 54.164.199.173:\n",
      "Traceback (most recent call last):\n",
      "  File \"cassandra/cluster.py\", line 2623, in cassandra.cluster.ControlConnection._reconnect_internal (cassandra/cluster.c:47899)\n",
      "    return self._try_connect(host)\n",
      "  File \"cassandra/cluster.py\", line 2645, in cassandra.cluster.ControlConnection._try_connect (cassandra/cluster.c:48416)\n",
      "    connection = self._cluster.connection_factory(host.address, is_control_connection=True)\n",
      "  File \"cassandra/cluster.py\", line 1119, in cassandra.cluster.Cluster.connection_factory (cassandra/cluster.c:15085)\n",
      "    return self.connection_class.factory(address, self.connect_timeout, *args, **kwargs)\n",
      "  File \"cassandra/connection.py\", line 324, in cassandra.connection.Connection.factory (cassandra/connection.c:5504)\n",
      "    conn = cls(host, *args, **kwargs)\n",
      "  File \"/Users/alessandro/anaconda/envs/dsci6007/lib/python2.7/site-packages/cassandra/io/asyncorereactor.py\", line 299, in __init__\n",
      "    self._connect_socket()\n",
      "  File \"cassandra/connection.py\", line 363, in cassandra.connection.Connection._connect_socket (cassandra/connection.c:6813)\n",
      "    raise socket.error(sockerr.errno, \"Tried connecting to %s. Last error: %s\" % ([a[4] for a in addresses], sockerr.strerror or sockerr))\n",
      "error: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 2.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 4.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 8.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 16.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 32.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 64.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 128.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 256.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 512.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 600.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 54.164.199.173, scheduling retry in 600.0 seconds: [Errno None] Tried connecting to [('54.164.199.173', 9042)]. Last error: timed out\n"
     ]
    }
   ],
   "source": [
    "tweet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: Could not parse Master URL: 'ec2-54-164-67-97.compute-1.amazonaws.com'\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2499)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:492)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:211)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2e77e5116a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ec2-54-164-67-97.compute-1.amazonaws.com'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/alessandro/zipfian/spark-2.0.0-bin-hadoop2.7/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[0;32m--> 115\u001b[0;31m                           conf, jsc, profiler_cls)\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alessandro/zipfian/spark-2.0.0-bin-hadoop2.7/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m_do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Create the Java SparkContext through Py4J\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alessandro/zipfian/spark-2.0.0-bin-hadoop2.7/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m_initialize_context\u001b[0;34m(self, jconf)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mInitialize\u001b[0m \u001b[0mSparkContext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mallow\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0minitialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJavaSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alessandro/anaconda/envs/dsci6007/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1401\u001b[0;31m             answer, self._gateway_client, None, self._fqn)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alessandro/anaconda/envs/dsci6007/lib/python2.7/site-packages/py4j/protocol.pyc\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: Could not parse Master URL: 'ec2-54-164-67-97.compute-1.amazonaws.com'\n\tat org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2499)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:492)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:240)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:211)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext('ec2-54-164-67-97.compute-1.amazonaws.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsci6007]",
   "language": "python",
   "name": "conda-env-dsci6007-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
