{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Hive Demo\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Hive Shell\n",
    "----------\n",
    "\n",
    "How can I start the Hive shell?\n",
    "\n",
    "- Start VirtualBox.\n",
    "\n",
    "- Select *Hortonworks Sandbox*\n",
    "\n",
    "- Holding down the *Shift* key click *Start*. This brings up the\n",
    "  machine headless.\n",
    "\n",
    "- Connect to it using `ssh -p 2222 root@127.0.0.1`\n",
    "\n",
    "- Use `hadoop` as the password.\n",
    "\n",
    "- Type `hive` to start the Hive shell.\n",
    "\n",
    "Hive Shell Commands\n",
    "-------------------\n",
    "\n",
    "What are some convenient commands in the Hive shell?\n",
    "\n",
    "Command                         |Meaning\n",
    "-------                         |-------\n",
    "`!ls;`                          |List files on local machine\n",
    "`dfs -ls;`                      |List files on HDFS\n",
    "`set mapred.reduce.tasks=32;`   |Set (Hadoop and/or Hive) configuration parameter\n",
    "`set mapred.reduce.tasks;`      |Print configuration parameter value\n",
    "`set;`                          |Print all overridden configuration parameter values\n",
    "`set -v;`                       |Print all configuration parameter values\n",
    "`source myscript.sql;`          |Run HiveQL script in shell\n",
    "`SHOW TABLES;`                  |List all tables\n",
    "`DESCRIBE sales;`               |Describe table `sales`\n",
    "`DESCRIBE FORMATTED sales;`     |Describe table `sales` in a lot of detail\n",
    "`quit;`                         |Exit the Hive shell\n",
    "\n",
    "Hive Scripting\n",
    "--------------\n",
    "\n",
    "How can I embed Hive into a batch script?\n",
    "\n",
    "Command                              |Meaning\n",
    "-------                              |-------\n",
    "`hive -e 'SELECT * FROM movies'`     |Run SQL and display result\n",
    "`hive -S -e 'SELECT * FROM movies'`  |Run SQL with less logging output and display result\n",
    "`hive -f hive-script.sql`            |Run SQL in `hive-script.sql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "Creating Tables\n",
    "----\n",
    "\n",
    "How To Create Tables\n",
    "--------------------\n",
    "\n",
    "How can I use Hive with data I already have in HDFS?\n",
    "\n",
    "### Upload data to HDFS\n",
    "\n",
    "```sh\n",
    "# Create sales.csv.\n",
    "cat <<'END_OF_DATA' > sales.csv\n",
    "#ID,Date,Store,State,Product,Amount\n",
    "101,2014-11-13,100,WA,331,300.00\n",
    "104,2014-11-18,700,OR,329,450.00\n",
    "102,2014-11-15,203,CA,321,200.00\n",
    "106,2014-11-19,202,CA,331,330.00\n",
    "103,2014-11-17,101,WA,373,750.00\n",
    "105,2014-11-19,202,CA,321,200.00\n",
    "END_OF_DATA\n",
    "\n",
    "# Upload it to HDFS.\n",
    "hadoop fs -rm -r /user/root/sales\n",
    "hadoop fs -mkdir /user/root/sales\n",
    "hadoop fs -put   sales.csv /user/root/sales/part1.csv\n",
    "\n",
    "# Test it was uploaded to HDFS.\n",
    "hadoop fs -ls -R /user/root/sales\n",
    "hadoop fs -cat \"/user/root/sales/*\"\n",
    "```\n",
    "\n",
    "### Create External Table\n",
    "\n",
    "In the Hive shell:\n",
    "\n",
    "```sql\n",
    "-- Drop table if it exists.\n",
    "DROP TABLE IF EXISTS  sales;\n",
    "\n",
    "-- Create external table.\n",
    "CREATE EXTERNAL TABLE sales(\n",
    "  id INT,\n",
    "  sale_date STRING,\n",
    "  store INT,\n",
    "  state STRING,\n",
    "  product INT,\n",
    "  amount DOUBLE\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/root/sales'\n",
    "TBLPROPERTIES(\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "-- Select table to test.\n",
    "SELECT * FROM sales;\n",
    "```\n",
    "\n",
    "Check for understanding: Creating Tables\n",
    "-------------------------\n",
    "\n",
    "<details><summary>\n",
    "Does `CREATE TABLE` have an effect on the MetaStore or on HDFS or\n",
    "both?\n",
    "</summary>\n",
    "1. Creating external tables adds metadata to existing HDFS data.<br>\n",
    "2. It only affects the metastore where the metadata is stored.<br>\n",
    "3. It does not affect the data in HDFS.<br>\n",
    "4. In fact you can create a table with no data in HDFS, and add the\n",
    "data later.<br>\n",
    "</details>\n",
    "\n",
    "Check for understanding: Creating Tables\n",
    "-------------------------\n",
    "\n",
    "<details><summary>\n",
    "Can I create multiple external tables on the same data in HDFS?\n",
    "</summary>\n",
    "It would be slightly weird, but yes, you can do this.\n",
    "</details>\n",
    "\n",
    "\n",
    "Internal and External Tables\n",
    "----------------------------\n",
    "\n",
    "What is the difference between *internal* and *external* tables?\n",
    "\n",
    "Command                       |Internal Table               |External Table\n",
    "-------                       |--------------               |--------------\n",
    "`CREATE TABLE`                |Default                      |Requires `EXTERNAL` keyword\n",
    "HDFS Location                 |`/user/hive/warehouse`       |User specifies location\n",
    "`DESCRIBE FORMATTED mytable`  |`TABLE TYPE: MANAGED_TABLE`  |`TABLE TYPE: EXTERNAL_TABLE`\n",
    "`DROP TABLE mytable`          |Deletes metadata + data      |Only deletes metadata\n",
    "\n",
    "Check for understanding\n",
    "--------\n",
    "\n",
    "<details><summary>\n",
    "I changed my mind about what I want to call the columns on my\n",
    "internal table. Should I drop the table and start over?\n",
    "</summary>\n",
    "1. Noooo!<br>\n",
    "2. Be very careful with `DROP` and internal tables.<br>\n",
    "3. Use `ALTER` instead.<br>\n",
    "4. Conceptually an internal table is a table for which Hive manages\n",
    "the data.<br>\n",
    "</details>\n",
    "\n",
    "Creating Internal Tables\n",
    "------------------------\n",
    "\n",
    "How can I create an internal table?\n",
    "\n",
    "- Use same syntax as `CREATE TABLE` but leave out `LOCATION` and\n",
    "  `EXTERNAL`.\n",
    "\n",
    "```sql\n",
    "-- Drop table if it exists.\n",
    "DROP TABLE IF EXISTS  sales_tmp;\n",
    "\n",
    "-- Create internal table.\n",
    "CREATE TABLE sales_tmp(\n",
    "  id INT,\n",
    "  sale_date STRING,\n",
    "  store INT,\n",
    "  state STRING,\n",
    "  product INT,\n",
    "  amount DOUBLE\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "TBLPROPERTIES(\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "-- Select table to test.\n",
    "SELECT * FROM sales_tmp;\n",
    "```\n",
    "\n",
    "Check for understanding: Internal Tables\n",
    "-------------------------\n",
    "\n",
    "<details><summary>\n",
    "What are some use cases for internal tables?\n",
    "</summary>\n",
    "1. You can use them for temporary data.<br>\n",
    "2. You can use them to share data between different users.<br>\n",
    "3. The delete-on-drop behavior matches the behavior of traditional databases.<br>\n",
    "</details>\n",
    "\n",
    "Data Ingestion\n",
    "==============\n",
    "\n",
    "Check for understanding: Why Ingest Data\n",
    "-------------------------\n",
    "\n",
    "<details><summary>\n",
    "What are some use cases for ingesting data?\n",
    "</summary>\n",
    "1. Internal tables start out with no data. After you create the table\n",
    "you have to ingest data into it.<br>\n",
    "2. If you have daily incoming data you have to ingest it into existing\n",
    "tables.<br>\n",
    "</details>\n",
    "\n",
    "How To Ingest Data\n",
    "------------------\n",
    "\n",
    "How can I ingest data into an existing table?\n",
    "\n",
    "### Shell\n",
    "\n",
    "```sh\n",
    "# Upload to HDFS.\n",
    "hadoop fs -rm -r /user/root/sales_tmp\n",
    "hadoop fs -mkdir /user/root/sales_tmp\n",
    "hadoop fs -put   sales.csv /user/root/sales_tmp/part1.csv\n",
    "\n",
    "# Test it was uploaded to HDFS.\n",
    "hadoop fs -ls -R /user/root/sales_tmp\n",
    "hadoop fs -cat \"/user/root/sales_tmp/*\"\n",
    "```\n",
    "\n",
    "### Hive\n",
    "\n",
    "```sql\n",
    "-- Load data to Hive.\n",
    "LOAD DATA \n",
    "INPATH '/user/root/sales_tmp' \n",
    "OVERWRITE \n",
    "INTO TABLE sales_tmp;\n",
    "\n",
    "-- Check it is in Hive.\n",
    "SELECT * FROM sales_tmp;\n",
    "```\n",
    "\n",
    "### Shell\n",
    "\n",
    "```bash\n",
    "# Check data in HDFS again.\n",
    "hadoop fs -ls -R /user/root/sales_tmp\n",
    "\n",
    "# Find location of data\n",
    "hive -e \"DESCRIBE FORMATTED sales_tmp;\"\n",
    "```\n",
    "\n",
    "### Hive\n",
    "\n",
    "```bash\n",
    "# Check data in Hive's warehouse dir. \n",
    "hadoop fs -ls -R /apps/hive/warehouse/sales_tmp\n",
    "```\n",
    "\n",
    "Check for understanding: Ingesting Data\n",
    "------------------------\n",
    "\n",
    "<details><summary>\n",
    "What happened to the data in HDFS when we ingested it?\n",
    "</summary>\n",
    "1. `LOAD DATA` moves the data to a Hive-managed directory.<br>\n",
    "2. The data is no longer where you uploaded it.<br>\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "Is the data for the internal tables stored in HDFS or in the metastore?\n",
    "</summary>\n",
    "1. The data is stored in HDFS.<br>\n",
    "2. The data will be too large for the metastore.<br>\n",
    "3. The metastore is stored in MySQL or some other small database.<br>\n",
    "4. It only has metadata: table names, table locations, column names, column types, etc. <br>\n",
    "5. It does not have any table data.<br>\n",
    "</details>\n",
    "\n",
    "\n",
    "Ingesting Data\n",
    "--------------\n",
    "\n",
    "What are the different ways of ingesting data and appending to the table?\n",
    "\n",
    "Commmand                                                 |Path On |Deletes Source\n",
    "--------                                                 |------- |--------------\n",
    "`LOAD DATA INPATH 'path' INTO TABLE t1`                  |HDFS    |Yes\n",
    "`LOAD DATA LOCAL INPATH 'path' INTO TABLE t1`            |Client  |No\n",
    "\n",
    "What are the different ways of ingesting data and overwriting the table?\n",
    "\n",
    "Commmand                                                 |Path On |Deletes Source\n",
    "--------                                                 |------- |--------------\n",
    "`LOAD DATA INPATH 'path' OVERWRITE INTO TABLE t1`        |HDFS    |Yes\n",
    "`LOAD DATA LOCAL INPATH 'path' OVERWRITE INTO TABLE t1`  |Client  |No\n",
    "\n",
    "\n",
    "Check for understanding: Dropping Tables\n",
    "-------------------------\n",
    "<details><summary>\n",
    "How can I drop a table I no longer need?\n",
    "</summary>\n",
    "1. `DROP TABLE sales;`<br>\n",
    "2. `DROP TABLE IF EXISTS sales;`<br>\n",
    "3. Using `IF EXISTS` is less error prone.<br>\n",
    "</details>\n",
    "\n",
    "Queries\n",
    "=======\n",
    "\n",
    "Select\n",
    "------\n",
    "\n",
    "Now that we have our data in Hive we can run `SELECT` on it.\n",
    "\n",
    "<details><summary>\n",
    "What are all the transactions that were more than $300?\n",
    "</summary>\n",
    "`SELECT * FROM sales WHERE amount > 300;`\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "How can I see the first 3 transactions?\n",
    "</summary>\n",
    "`SELECT * FROM sales LIMIT 3;`\n",
    "</details>\n",
    "\n",
    "Aggregating Using Group By\n",
    "--------------------------\n",
    "\n",
    "How can we find the total sales per state?\n",
    "\n",
    "```sql\n",
    "SELECT state, SUM(amount) \n",
    "FROM sales\n",
    "GROUP BY state;\n",
    "```\n",
    "\n",
    "Aggregate Functions\n",
    "-------------------\n",
    "\n",
    "How can we find the average sales per state?\n",
    "\n",
    "```sql\n",
    "SELECT state, AVG(amount) \n",
    "FROM states \n",
    "GROUP BY state;\n",
    "```\n",
    "\n",
    "Functions\n",
    "---------\n",
    "\n",
    "Where can I get more details about all the Hive functions?\n",
    "\n",
    "- [Hive Documentation: Built-in Functions][hive-funcs]\n",
    "\n",
    "- Hive has built-in boolean operators, mathematical functions, string functions,\n",
    "  aggregate functions, and many others.\n",
    "\n",
    "- It also lets you write your custom *User-Define Functions* (UDFs) and\n",
    "  *User-Defined Aggregate Functions* (UDAFs) using Java, Python, and other\n",
    "  languages.\n",
    "\n",
    "[hive-funcs]: https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF\n",
    "\n",
    "Sorting\n",
    "=======\n",
    "\n",
    "Sorting Data\n",
    "------------\n",
    "\n",
    "How can I sort the transactions ordered by amount, highest first?\n",
    "\n",
    "- Set the number of reducers to 2.\n",
    "\n",
    "```sql\n",
    "set mapred.reduce.tasks=2;\n",
    "```\n",
    "\n",
    "- Compare the output of `SORT BY` and `DISTRIBUTE BY`.\n",
    "\n",
    "- Why is `SORT BY` not sorting the result?\n",
    "\n",
    "```sql\n",
    "SELECT * FROM sales SORT BY amount DESC;\n",
    "SELECT * FROM sales DISTRIBUTE BY amount SORT BY amount DESC;\n",
    "```\n",
    "\n",
    "Sorting Options\n",
    "---------------\n",
    "\n",
    "What are the different ways I can sort data in Hive?\n",
    "\n",
    "```sql\n",
    "SELECT * FROM sales ORDER BY amount DESC;\n",
    "SELECT * FROM sales SORT BY amount DESC;\n",
    "SELECT * FROM sales CLUSTER BY amount; \n",
    "SELECT * FROM sales DISTRIBUTE BY amount SORT BY amount DESC;\n",
    "```\n",
    "\n",
    "### Order By\n",
    "\n",
    "`ORDER BY x`\n",
    "\n",
    "- Uses only 1 reducer\n",
    "- Reducer's output is sorted\n",
    "- Does not scale for large datasets when you need more reducers\n",
    "\n",
    "### Sort By\n",
    "\n",
    "`SORT BY x`\n",
    "\n",
    "- Each reducer's output is sorted\n",
    "- Concatenated result is **not** sorted\n",
    "\n",
    "### Distribute By\n",
    "\n",
    "`DISTRIBUTE BY x` \n",
    "\n",
    "- The output of each reducer is not sorted \n",
    "- The output of each reducer is ordered relative to output of other reducers\n",
    "- Partitions data so that the lower-index reducers get smaller keys\n",
    "\n",
    "### Cluster By\n",
    "\n",
    "`CLUSTER BY x` \n",
    "\n",
    "- Combines `DISTRIBUTE BY` and `SORT BY`\n",
    "- Partitions the data so the output of each reducer is ordered relative to others\n",
    "- Sorts the output of each reducer \n",
    "- Produces globally sorted output\n",
    "- Scalable version of `ORDER BY`\n",
    "- Does not support `DESC`\n",
    "\n",
    "Check for understanding: Sorting\n",
    "-----------------\n",
    "\n",
    "<details><summary>\n",
    "How should I sort a small sales table on amount?\n",
    "</summary>\n",
    "`SELECT * FROM sales ORDER BY amount DESC;`\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "How can I sort a large sales table in ascending order?\n",
    "</summary>\n",
    "`SELECT * FROM sales CLUSTER BY amount;`\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "How can I sort a large sales table in descending order?\n",
    "</summary>\n",
    "`SELECT * FROM sales DISTRIBUTE BY amount SORT BY amount DESC;`\n",
    "</details>\n",
    "\n",
    "\n",
    "Inserting Data\n",
    "==============\n",
    "\n",
    "Using Insert/Select to Save Data\n",
    "--------------------------------\n",
    "\n",
    "How can save the results of calculating the average sales?\n",
    "\n",
    "```sql\n",
    "-- Create the table.\n",
    "CREATE TABLE sales_avg(\n",
    "  state STRING,\n",
    "  amount DOUBLE\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "TBLPROPERTIES(\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "-- Insert selected data.\n",
    "INSERT OVERWRITE TABLE sales_avg \n",
    "SELECT states.state, AVG(amount) \n",
    "FROM states \n",
    "LEFT OUTER JOIN sales \n",
    "ON sales.state = states.state \n",
    "GROUP BY states.state;\n",
    "```\n",
    "\n",
    "### Shell \n",
    "\n",
    "```bash\n",
    "# Check that table has data.\n",
    "hadoop fs -ls -R /apps/hive/warehouse/sales_avg\n",
    "hadoop fs -cat \"/apps/hive/warehouse/sales_avg/*\"\n",
    "```\n",
    "\n",
    "Insert/Select Details\n",
    "---------------------\n",
    "\n",
    "How can I use `SELECT` to append to a table instead of overwriting it?\n",
    "\n",
    "### Hive\n",
    "\n",
    "```sql\n",
    "-- Append selected data.\n",
    "INSERT INTO TABLE sales_avg \n",
    "SELECT states.state, AVG(amount) \n",
    "FROM states \n",
    "LEFT OUTER JOIN sales \n",
    "ON sales.state = states.state \n",
    "GROUP BY states.state;\n",
    "```\n",
    "\n",
    "### Shell\n",
    "\n",
    "```bash\n",
    "# Check that table has data.\n",
    "hadoop fs -ls -R /apps/hive/warehouse/sales_avg\n",
    "hadoop fs -cat \"/apps/hive/warehouse/sales_avg/*\"\n",
    "```\n",
    "\n",
    "Check for understanding: Insert/Select Notes\n",
    "-----------------------------\n",
    "\n",
    "<details><summary>\n",
    "What is a quick way to delete the contents of a table?\n",
    "</summary>\n",
    "`INSERT OVERWRITE TABLE sales_avg SELECT * FROM sales_avg WHERE 1 = 0;`\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Congrats: You Get a SQL chameleon!\n",
    "----\n",
    "\n",
    "![](http://www.jmordax.com/imagenes/sql.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
